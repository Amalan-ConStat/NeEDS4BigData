<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="NeEDS4BigData">
<title>Introduction • NeEDS4BigData</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.11/clipboard.min.js" integrity="sha512-7O5pXpc0oCRrxk8RUfDYFgn0nO1t+jLuIOQdOMRp4APB7uZ4vSjspzp5y6YDtDs4VzUSTbWzBFZ/LKJhnyFOKw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Introduction">
<meta property="og:description" content="NeEDS4BigData">
<meta property="og:image" content="/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light" data-bs-theme="light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">NeEDS4BigData</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">1.0.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Functions</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-examples">Examples</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-examples">
    <a class="dropdown-item" href="../articles/introduction.html">Introduction</a>
    <a class="dropdown-item" href="../articles/Basic_Sampling_Lin_Reg.html">Linear Regression - Basic sampling</a>
    <a class="dropdown-item" href="../articles/Linear_Regression.html">Linear Regression - Model robust and misspecification</a>
    <a class="dropdown-item" href="../articles/Basic_Sampling_Log_Reg.html">Logistic Regression - Basic sampling</a>
    <a class="dropdown-item" href="../articles/Logistic_Regression.html">Logistic Regression - Model robust and misspecification</a>
    <a class="dropdown-item" href="../articles/Basic_Sampling_Poi_Reg.html">Poisson Regression - Basic sampling</a>
    <a class="dropdown-item" href="../articles/Poisson_Regression.html">Poisson Regression - Model robust and misspecification</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Versions</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="http://www.amalan-mahendran.com">
    <span class="fa fa-user-circle"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://twitter.com/Amalan_Con_Stat">
    <span class="fa fa-hashtag"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://bsky.app/profile/amalanconstat.bsky.social">
    <span class="fa fa-twitter"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/Amalan-ConStat">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://www.linkedin.com/in/amalan-mahendran-72b86b37/">
    <span class="fa fa-linkedin"></span>
     
  </a>
</li>
<li class="nav-item">
  <a class="external-link nav-link" href="https://scholar.google.com/citations?user=fj4E-GMAAAAJ&amp;hl=en">
    <span class="fa fa-google"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Introduction</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/Amalan-ConStat/NeEDS4BigData/blob/HEAD/vignettes/Introduction.Rmd" class="external-link"><code>vignettes/Introduction.Rmd</code></a></small>
      <div class="d-none name"><code>Introduction.Rmd</code></div>
    </div>

    
    
<style>
body {
text-align: justify}
</style>
<div class="section level2">
<h2 id="big-data-analysis">Big data analysis<a class="anchor" aria-label="anchor" href="#big-data-analysis"></a>
</h2>
<p>Big data presents both promising opportunities and formidable
challenges for data analysts and scientists. However, its massive scale
and complexity introduces novel computational and statistical hurdles.
These include scalability issues, storage constraints, noise
accumulation, spurious correlations, incidental endogeneity and
measurement errors. Addressing these challenges demands innovative
approaches in both computation and statistics. Traditional methods,
effective for small and moderate sample sizes, often falter when
confronted with massive datasets. Thus, there is a pressing need for
innovative statistical methodologies and computational tools tailored to
the unique demands of big data analysis.</p>
<div class="float">
<img src="../reference/figures/Figure_1.webp" alt="The continuously increasing size of big data from ``Big Data: A Survey”."><div class="figcaption">The continuously increasing size of big data
from ``Big Data: A Survey”.</div>
</div>
</div>
<div class="section level2">
<h2 id="computational-solutions-for-big-data-analysis">Computational solutions for big data analysis<a class="anchor" aria-label="anchor" href="#computational-solutions-for-big-data-analysis"></a>
</h2>
<p>Computer engineers often seek more powerful computing facilities to
reduce computing time, leading to the rapid development of
supercomputers over the past decade. These supercomputers boast speeds
and storage capacities hundreds or even thousands of times greater than
those of general-purpose PCs. However, their significant energy
consumption and limited accessibility to ordinary users remain major
drawbacks. While cloud computing offers a partial solution by providing
accessible computing resources, it faces challenges related to data
transfer inefficiency, privacy and security concerns. Graphic Processing
Units (GPUs) have emerged as another computational facility, offering
powerful parallel computing capabilities. However, recent comparisons
have shown that even high-end GPUs can be outperformed by
general-purpose multi-core processors, primarily due to data transfer
inefficiencies. In summary, neither supercomputers, cloud computing, nor
GPUs have efficiently solved the big data problem. Instead, there is a
growing need for efficient statistical solutions that can make big data
manageable on general-purpose PCs.</p>
</div>
<div class="section level2">
<h2 id="statistical-solutions-for-big-data-analysis">Statistical solutions for big data analysis<a class="anchor" aria-label="anchor" href="#statistical-solutions-for-big-data-analysis"></a>
</h2>
<p>In the realm of addressing the challenges posed by big data,
statistical solutions are relatively novel compared to engineering
solutions, with new methodologies continually under development.
Currently available methods can be broadly categorized into three
groups:</p>
<ol style="list-style-type: decimal">
<li>Sampling Method: Sampling involves selecting a representative subset
of the data for analysis instead of analysing the entire dataset. This
approach can significantly reduce computational requirements while still
providing valuable insights into the underlying population.</li>
<li>Divide and conquer method: This approach involves breaking down the
large problem into smaller, more manageable sub problems. Each sub
problem is then independently analysed, often in parallel, before
combining the results to obtain the final output.</li>
<li>Online updating of streamed data: The statistical inference is
updated as new data arrive sequentially.</li>
</ol>
<p>In recent years, there has been a growing preference for subsampling
over divide and recombine methods in addressing a range of regression
problems. Meanwhile, online updating is primarily utilized for streaming
data. Furthermore, when a large dataset is unnecessary to confidently
answer a specific question, subsampling is often favoured, as it allows
for analysis using standard methods.</p>
</div>
<div class="section level2">
<h2 id="subsampling-algorithms-for-big-data">Subsampling algorithms for big data<a class="anchor" aria-label="anchor" href="#subsampling-algorithms-for-big-data"></a>
</h2>
<p>The literature presents two strategies to resolve the primary
challenge of how to acquire an informative subset that efficiently
addresses specific analytical questions and yield results consistent
with analysing the large data set.</p>
<p>They are:</p>
<ol style="list-style-type: decimal">
<li>Sample randomly from the large dataset using subsampling
probabilities determined via an assumed statistical model and objective
(e.g., prediction and/or parameter estimation) <span class="citation">(Wang, Zhu, and Ma 2018; Yao and Wang 2019; Ai, Wang,
et al. 2021; Ai, Yu, et al. 2021; Lee, Schifano, and Wang 2021, 2022;
Zhang, Ning, and Ruppert 2021)</span>
</li>
<li>Select subsamples based on an experimental design <span class="citation">(Drovandi et al. 2017; Wang, Yang, and Stufken 2019;
Cheng, Wang, and Yang 2020; Hou-Liu and Browne 2023; Reuter and Schwabe
2023; Yu, Liu, and Wang 2023)</span>.</li>
</ol>
<p>As of now in this package we focus on the subsampling methods</p>
<ol style="list-style-type: decimal">
<li>Leverage sampling by <span class="citation">Ma, Mahoney, and Yu
(2014)</span> and <span class="citation">Ma and Sun (2015)</span>.</li>
<li>Local case control sampling by <span class="citation">Fithian and
Hastie (2015)</span>.</li>
<li>A- and L-optimality based subsampling methods for Generalised Linear
Models by <span class="citation">Wang, Zhu, and Ma (2018)</span> and
<span class="citation">Ai, Yu, et al. (2021)</span>.</li>
<li>A-optimality based subsampling for Gaussian Linear Model by <span class="citation">Lee, Schifano, and Wang (2021)</span>.</li>
<li>A- and L-optimality based subsampling methods for Generalised Linear
Models under response not involved in probability calculation by <span class="citation">Zhang, Ning, and Ruppert (2021)</span>.</li>
<li>A- and L-optimality based model robust/average subsampling methods
for Generalised Linear Models by <span class="citation">Mahendran,
Thompson, and McGree (2023)</span>.</li>
<li>Subsampling for Generalised Linear Models under potential model
misspecification as by <span class="citation">Adewale and Wiens
(2009)</span> and <span class="citation">Adewale and Xu
(2010)</span>.</li>
</ol>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-adewale2009robust" class="csl-entry">
Adewale, Adeniyi J, and Douglas P Wiens. 2009. <span>“Robust Designs for
Misspecified Logistic Models.”</span> <em>Journal of Statistical
Planning and Inference</em> 139 (1): 3–15.
</div>
<div id="ref-adewale2010robust" class="csl-entry">
Adewale, Adeniyi J, and Xiaojian Xu. 2010. <span>“Robust Designs for
Generalized Linear Models with Possible Overdispersion and Misspecified
Link Functions.”</span> <em>Computational Statistics &amp; Data
Analysis</em> 54 (4): 875–90.
</div>
<div id="ref-ai2020quantile" class="csl-entry">
Ai, Mingyao, Fei Wang, Jun Yu, and Huiming Zhang. 2021. <span>“<span class="nocase">Optimal subsampling for large-scale quantile
regression</span>.”</span> <em>Journal of Complexity</em> 62: 101512. <a href="https://doi.org/10.1016/j.jco.2020.101512" class="external-link">https://doi.org/10.1016/j.jco.2020.101512</a>.
</div>
<div id="ref-ai2021optimal" class="csl-entry">
Ai, Mingyao, Jun Yu, Huiming Zhang, and HaiYing Wang. 2021.
<span>“Optimal Subsampling Algorithms for Big Data Regressions.”</span>
<em>Statistica Sinica</em> 31 (2): 749–72.
</div>
<div id="ref-cheng2020information" class="csl-entry">
Cheng, Qianshun, HaiYing Wang, and Min Yang. 2020.
<span>“Information-Based Optimal Subdata Selection for Big Data Logistic
Regression.”</span> <em>Journal of Statistical Planning and
Inference</em> 209: 112–22. <a href="https://doi.org/10.1016/j.jspi.2020.03.004" class="external-link">https://doi.org/10.1016/j.jspi.2020.03.004</a>.
</div>
<div id="ref-drovandi2017principles" class="csl-entry">
Drovandi, Christopher C, Christopher Holmes, James M McGree, Kerrie
Mengersen, Sylvia Richardson, and Elizabeth G Ryan. 2017. <span>“<span class="nocase">Principles of experimental design for big data
analysis</span>.”</span> <em>Statistical Science</em> 32 (3): 385–404.
<a href="https://doi.org/10.1214/16-STS604" class="external-link">https://doi.org/10.1214/16-STS604</a>.
</div>
<div id="ref-fithian2015local" class="csl-entry">
Fithian, William, and Trevor Hastie. 2015. <span>“Local Case-Control
Sampling: Efficient Subsampling in Imbalanced Data Sets.”</span>
<em>Quality Control and Applied Statistics</em> 60 (3): 187–90.
</div>
<div id="ref-hou2023generalized" class="csl-entry">
Hou-Liu, Jason, and Ryan P Browne. 2023. <span>“Generalized Linear
Models for Massive Data via Doubly-Sketching.”</span> <em>Statistics and
Computing</em> 33 (5): 105. <a href="https://doi.org/10.1007/s11222-023-10274-8" class="external-link">https://doi.org/10.1007/s11222-023-10274-8</a>.
</div>
<div id="ref-lee2021fast" class="csl-entry">
Lee, JooChul, Elizabeth D Schifano, and HaiYing Wang. 2021. <span>“<span class="nocase">Fast optimal subsampling probability approximation for
generalized linear models</span>.”</span> <em>Econometrics and
Statistics</em>. <a href="https://doi.org/10.1016/j.ecosta.2021.02.007" class="external-link">https://doi.org/10.1016/j.ecosta.2021.02.007</a>.
</div>
<div id="ref-lee2022sampling" class="csl-entry">
———. 2022. <span>“Sampling-Based Gaussian Mixture Regression for Big
Data.”</span> <em>Journal of Data Science</em> 21 (1): 158–72. <a href="https://doi.org/10.6339/22-JDS1057" class="external-link">https://doi.org/10.6339/22-JDS1057</a>.
</div>
<div id="ref-ma2014statistical" class="csl-entry">
Ma, Ping, Michael Mahoney, and Bin Yu. 2014. <span>“A Statistical
Perspective on Algorithmic Leveraging.”</span> In <em>International
Conference on Machine Learning</em>, 91–99. PMLR.
</div>
<div id="ref-ma2015leveraging" class="csl-entry">
Ma, Ping, and Xiaoxiao Sun. 2015. <span>“Leveraging for Big Data
Regression.”</span> <em>Wiley Interdisciplinary Reviews: Computational
Statistics</em> 7 (1): 70–76.
</div>
<div id="ref-mahendran2023model" class="csl-entry">
Mahendran, Amalan, Helen Thompson, and James M McGree. 2023. <span>“A
Model Robust Subsampling Approach for Generalised Linear Models in Big
Data Settings.”</span> <em>Statistical Papers</em> 64 (4): 1137–57.
</div>
<div id="ref-reuter2023optimal" class="csl-entry">
Reuter, Torsten, and Rainer Schwabe. 2023. <span>“Optimal Subsampling
Design for Polynomial Regression in One Covariate.”</span>
<em>Statistical Papers</em>, 1–23. <a href="https://doi.org/10.1007/s00362-023-01425-0" class="external-link">https://doi.org/10.1007/s00362-023-01425-0</a>.
</div>
<div id="ref-wang2019information" class="csl-entry">
Wang, HaiYing, Min Yang, and John Stufken. 2019.
<span>“Information-Based Optimal Subdata Selection for Big Data Linear
Regression.”</span> <em>Journal of the American Statistical
Association</em> 114 (525): 393–405. <a href="https://doi.org/10.1080/01621459.2017.1408468" class="external-link">https://doi.org/10.1080/01621459.2017.1408468</a>.
</div>
<div id="ref-wang2018optimal" class="csl-entry">
Wang, HaiYing, Rong Zhu, and Ping Ma. 2018. <span>“Optimal Subsampling
for Large Sample Logistic Regression.”</span> <em>Journal of the
American Statistical Association</em> 113 (522): 829–44.
</div>
<div id="ref-yao2019softmax" class="csl-entry">
Yao, Yaqiong, and HaiYing Wang. 2019. <span>“<span class="nocase">Optimal subsampling for softmax
regression</span>.”</span> <em>Statistical Papers</em> 60 (2): 585–99.
<a href="https://doi.org/10.1007/s00362-018-01068-6" class="external-link">https://doi.org/10.1007/s00362-018-01068-6</a>.
</div>
<div id="ref-yu2023information" class="csl-entry">
Yu, Jun, Jiaqi Liu, and HaiYing Wang. 2023. <span>“Information-Based
Optimal Subdata Selection for Non-Linear Models.”</span> <em>Statistical
Papers</em>, 1–25. <a href="https://doi.org/10.1007/s00362-023-01430-3" class="external-link">https://doi.org/10.1007/s00362-023-01430-3</a>.
</div>
<div id="ref-zhang2021optimal" class="csl-entry">
Zhang, Tao, Yang Ning, and David Ruppert. 2021. <span>“Optimal Sampling
for Generalized Linear Models Under Measurement Constraints.”</span>
<em>Journal of Computational and Graphical Statistics</em> 30 (1):
106–14.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://www.amalan-mahendran.com" class="external-link">Amalan Mahendran</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
